






<!doctype html>
<html
  lang="en"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="light"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>Computer Vision for Edge Deployment &middot; 0xsersif // Full-Stack Developer & ML Engineer</title>
    <meta name="title" content="Computer Vision for Edge Deployment &middot; 0xsersif // Full-Stack Developer & ML Engineer" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="http://localhost:1313/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
    
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="http://localhost:1313/css/main.bundle.min.b03e5259dac2760f0e3006bed7d970a363f24345198646bec6dbd9d2fb966a12.css"
    integrity="sha256-sD5SWdrCdg8OMAa&#43;19lwo2PyQ0UZhka&#43;xtvZ0vuWahI="
  />
  
  
  
  
  
  
  
  <meta
    name="description"
    content="
      YOLO object detection optimized for Raspberry Pi and mobile edge devices
    "
  />
  
  
  
  
    <link rel="canonical" href="http://localhost:1313/projects/cv-edge-deployment/" />
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://localhost:1313/projects/cv-edge-deployment/">
  <meta property="og:site_name" content="0xsersif // Full-Stack Developer & ML Engineer">
  <meta property="og:title" content="Computer Vision for Edge Deployment">
  <meta property="og:description" content="YOLO object detection optimized for Raspberry Pi and mobile edge devices">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="projects">
    <meta property="article:published_time" content="2025-11-20T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-11-20T00:00:00+00:00">
    <meta property="article:tag" content="Computer Vision">
    <meta property="article:tag" content="Edge AI">
    <meta property="article:tag" content="YOLO">
    <meta property="article:tag" content="PyTorch">
    <meta property="article:tag" content="ONNX">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Computer Vision for Edge Deployment">
  <meta name="twitter:description" content="YOLO object detection optimized for Raspberry Pi and mobile edge devices">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Projects",
    "name": "Computer Vision for Edge Deployment",
    "headline": "Computer Vision for Edge Deployment",
    "description": "YOLO object detection optimized for Raspberry Pi and mobile edge devices",
    "abstract": "\u003ch1 id=\u0022computer-vision-for-edge-deployment\u0022 class=\u0022relative group\u0022\u003eComputer Vision for Edge Deployment \u003cspan class=\u0022absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\u0022\u003e\u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022 style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#computer-vision-for-edge-deployment\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\u003c\/span\u003e\u003c\/h1\u003e\u003ch2 id=\u0022project-overview\u0022 class=\u0022relative group\u0022\u003eProject Overview \u003cspan class=\u0022absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\u0022\u003e\u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022 style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#project-overview\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\u003c\/span\u003e\u003c\/h2\u003e\u003cp\u003eDeploy a real-time \u003cstrong\u003eobject detection model (YOLO)\u003c\/strong\u003e on resource-constrained edge devices (Raspberry Pi 4, mobile phones) through aggressive model optimization and quantization.\u003c\/p\u003e\n\u003ch2 id=\u0022why-edge-deployment\u0022 class=\u0022relative group\u0022\u003eWhy Edge Deployment? \u003cspan class=\u0022absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\u0022\u003e\u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022 style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#why-edge-deployment\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\u003c\/span\u003e\u003c\/h2\u003e\u003cp\u003e\u003cstrong\u003eChallenges\u003c\/strong\u003e:\u003c\/p\u003e\n\u003cul\u003e\n\u003cli\u003eLimited compute (ARM CPU, no GPU)\u003c\/li\u003e\n\u003cli\u003eConstrained memory (2-4GB RAM)\u003c\/li\u003e\n\u003cli\u003eReal-time requirements (\u0026lt;100ms inference)\u003c\/li\u003e\n\u003cli\u003eBattery constraints (mobile)\u003c\/li\u003e\n\u003c\/ul\u003e\n\u003cp\u003e\u003cstrong\u003eBenefits\u003c\/strong\u003e:\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "http:\/\/localhost:1313\/projects\/cv-edge-deployment\/",
    "author" : {
      "@type": "Person",
      "name": "0xsersif"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-11-20T00:00:00\u002b00:00",
    "datePublished": "2025-11-20T00:00:00\u002b00:00",
    
    "dateModified": "2025-11-20T00:00:00\u002b00:00",
    
    "keywords": ["Computer Vision","Edge AI","YOLO","PyTorch","ONNX"],
    
    "mainEntityOfPage": "true",
    "wordCount": "738"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/",
       "name": "",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/projects/",
       "name": "Projects",
       "position": 2
     },
     {
       "@type": "ListItem",
       "item": "http://localhost:1313/categories/core-ml-engineering/",
       "name": "Core ML Engineering",
       "position": 3
     },
     {
       "@type": "ListItem",
       "name": "Computer Vision for Edge Deployment",
       "position": 4
     }
   ]
 }
  </script>

  
  
    <meta name="author" content="0xsersif" />
  
  
  
  







  
  

  
  
</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >0xsersif // Full-Stack Developer &amp; ML Engineer</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/about/"
                  title="About"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >About</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/projects/"
                  title="Projects"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Projects</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/philosophy/"
                  title="Development Philosophy &amp; MLOps Practices"
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Philosophy</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/self-learning-path/"
                  title=""
                  
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Self-Learning Path</span
                    >
                  </a
                >
              
            </li>
          
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
      <h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Computer Vision for Edge Deployment
      </h1>
      
        <div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
          





  
  



  

  
  
    
  

  

  

  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-11-20 00:00:00 &#43;0000 UTC">20 November 2025</time>
    

    
    
  </div>

  
  


        </div>
      
      
    </header>
    <section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row">
      
      <div class="min-h-0 min-w-0 max-w-prose grow">
        <h1 id="computer-vision-for-edge-deployment" class="relative group">Computer Vision for Edge Deployment <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#computer-vision-for-edge-deployment" aria-label="Anchor">#</a></span></h1><h2 id="project-overview" class="relative group">Project Overview <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#project-overview" aria-label="Anchor">#</a></span></h2><p>Deploy a real-time <strong>object detection model (YOLO)</strong> on resource-constrained edge devices (Raspberry Pi 4, mobile phones) through aggressive model optimization and quantization.</p>
<h2 id="why-edge-deployment" class="relative group">Why Edge Deployment? <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#why-edge-deployment" aria-label="Anchor">#</a></span></h2><p><strong>Challenges</strong>:</p>
<ul>
<li>Limited compute (ARM CPU, no GPU)</li>
<li>Constrained memory (2-4GB RAM)</li>
<li>Real-time requirements (&lt;100ms inference)</li>
<li>Battery constraints (mobile)</li>
</ul>
<p><strong>Benefits</strong>:</p>
<ul>
<li>No cloud dependency (offline operation)</li>
<li>Low latency (no network round-trip)</li>
<li>Privacy (data stays on device)</li>
<li>Cost savings (no cloud inference fees)</li>
</ul>
<h2 id="model-selection-yolov8" class="relative group">Model Selection: YOLOv8 <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#model-selection-yolov8" aria-label="Anchor">#</a></span></h2><p>Chose <strong>YOLOv8-Nano</strong> for edge deployment:</p>
<ul>
<li>Smallest YOLO variant (3M parameters)</li>
<li>Good accuracy/speed tradeoff</li>
<li>Proven on mobile devices</li>
</ul>
<p><strong>Baseline Performance (desktop GPU)</strong>:</p>
<ul>
<li>FPS: 120</li>
<li>mAP50: 37.3%</li>
<li>Latency: 8ms</li>
</ul>
<h2 id="optimization-pipeline" class="relative group">Optimization Pipeline <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#optimization-pipeline" aria-label="Anchor">#</a></span></h2><h3 id="1-model-quantization" class="relative group">1. Model Quantization <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#1-model-quantization" aria-label="Anchor">#</a></span></h3><p>Convert FP32 â†’ INT8 (4x smaller, 4x faster):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#ff79c6">from</span> torch.quantization <span style="color:#ff79c6">import</span> quantize_dynamic
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#ff79c6">=</span> torch<span style="color:#ff79c6">.</span>load(<span style="color:#f1fa8c">&#34;yolov8n.pt&#34;</span>)
</span></span><span style="display:flex;"><span>quantized_model <span style="color:#ff79c6">=</span> quantize_dynamic(
</span></span><span style="display:flex;"><span>    model, {torch<span style="color:#ff79c6">.</span>nn<span style="color:#ff79c6">.</span>Linear}, dtype<span style="color:#ff79c6">=</span>torch<span style="color:#ff79c6">.</span>qint8
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><strong>Result</strong>: 12MB â†’ 3MB model size</p>
<h3 id="2-onnx-export" class="relative group">2. ONNX Export <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#2-onnx-export" aria-label="Anchor">#</a></span></h3><p>Export to ONNX for cross-platform inference:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>torch<span style="color:#ff79c6">.</span>onnx<span style="color:#ff79c6">.</span>export(
</span></span><span style="display:flex;"><span>    model, dummy_input, <span style="color:#f1fa8c">&#34;yolov8n.onnx&#34;</span>,
</span></span><span style="display:flex;"><span>    opset_version<span style="color:#ff79c6">=</span><span style="color:#bd93f9">13</span>,
</span></span><span style="display:flex;"><span>    input_names<span style="color:#ff79c6">=</span>[<span style="color:#f1fa8c">&#34;images&#34;</span>],
</span></span><span style="display:flex;"><span>    output_names<span style="color:#ff79c6">=</span>[<span style="color:#f1fa8c">&#34;output&#34;</span>]
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><h3 id="3-tensorflow-lite-conversion" class="relative group">3. TensorFlow Lite Conversion <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#3-tensorflow-lite-conversion" aria-label="Anchor">#</a></span></h3><p>For mobile (Android/iOS):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>converter <span style="color:#ff79c6">=</span> tf<span style="color:#ff79c6">.</span>lite<span style="color:#ff79c6">.</span>TFLiteConverter<span style="color:#ff79c6">.</span>from_saved_model(<span style="color:#f1fa8c">&#34;model&#34;</span>)
</span></span><span style="display:flex;"><span>converter<span style="color:#ff79c6">.</span>optimizations <span style="color:#ff79c6">=</span> [tf<span style="color:#ff79c6">.</span>lite<span style="color:#ff79c6">.</span>Optimize<span style="color:#ff79c6">.</span>DEFAULT]
</span></span><span style="display:flex;"><span>tflite_model <span style="color:#ff79c6">=</span> converter<span style="color:#ff79c6">.</span>convert()
</span></span></code></pre></div><h3 id="4-pruning" class="relative group">4. Pruning <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#4-pruning" aria-label="Anchor">#</a></span></h3><p>Remove 30% of least important weights:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> torch.nn.utils.prune <span style="color:#ff79c6">as</span> prune
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>prune<span style="color:#ff79c6">.</span>l1_unstructured(
</span></span><span style="display:flex;"><span>    model<span style="color:#ff79c6">.</span>conv1, name<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;weight&#34;</span>, amount<span style="color:#ff79c6">=</span><span style="color:#bd93f9">0.3</span>
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></div><p><strong>Result</strong>: Minimal accuracy drop (-2% mAP), 20% faster</p>
<h3 id="5-neural-architecture-search-nas" class="relative group">5. Neural Architecture Search (NAS) <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#5-neural-architecture-search-nas" aria-label="Anchor">#</a></span></h3><p>Automated model architecture optimization for ARM:</p>
<ul>
<li>Reduce channel dimensions</li>
<li>Replace expensive operations (e.g., SiLU â†’ ReLU)</li>
<li>Optimize kernel sizes for ARM NEON</li>
</ul>
<h2 id="tech-stack" class="relative group">Tech Stack <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#tech-stack" aria-label="Anchor">#</a></span></h2><ul>
<li><strong>PyTorch</strong> â€” Model training and export</li>
<li><strong>ONNX Runtime</strong> â€” Cross-platform inference</li>
<li><strong>TensorFlow Lite</strong> â€” Mobile deployment</li>
<li><strong>OpenCV</strong> â€” Video capture and preprocessing</li>
<li><strong>NumPy</strong> â€” Array operations</li>
<li><strong>Raspberry Pi 4</strong> â€” Edge hardware (ARM Cortex-A72)</li>
</ul>
<h2 id="deployment-targets" class="relative group">Deployment Targets <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#deployment-targets" aria-label="Anchor">#</a></span></h2><h3 id="raspberry-pi-4-2gb-ram" class="relative group">Raspberry Pi 4 (2GB RAM) <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#raspberry-pi-4-2gb-ram" aria-label="Anchor">#</a></span></h3><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#ff79c6">import</span> onnxruntime <span style="color:#ff79c6">as</span> ort
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>session <span style="color:#ff79c6">=</span> ort<span style="color:#ff79c6">.</span>InferenceSession(<span style="color:#f1fa8c">&#34;yolov8n_int8.onnx&#34;</span>)
</span></span><span style="display:flex;"><span>outputs <span style="color:#ff79c6">=</span> session<span style="color:#ff79c6">.</span>run(<span style="color:#ff79c6">None</span>, {<span style="color:#f1fa8c">&#34;images&#34;</span>: frame})
</span></span></code></pre></div><p><strong>Performance</strong>:</p>
<ul>
<li>FPS: <strong>12</strong> (quantized) vs 3 (baseline)</li>
<li>Latency: <strong>80ms</strong> (P95)</li>
<li>Power: 3W average</li>
</ul>
<h3 id="mobile-android" class="relative group">Mobile (Android) <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#mobile-android" aria-label="Anchor">#</a></span></h3><p>TensorFlow Lite integration:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-kotlin" data-lang="kotlin"><span style="display:flex;"><span><span style="color:#ff79c6">val</span> interpreter = Interpreter(loadModelFile())
</span></span><span style="display:flex;"><span>interpreter.run(inputBuffer, outputBuffer)
</span></span></code></pre></div><p><strong>Performance</strong>:</p>
<ul>
<li>FPS: <strong>18</strong> on Snapdragon 865</li>
<li>Battery: 4 hours continuous detection</li>
</ul>
<h2 id="use-cases" class="relative group">Use Cases <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#use-cases" aria-label="Anchor">#</a></span></h2><h3 id="1-smart-home-security-raspberry-pi" class="relative group">1. Smart Home Security (Raspberry Pi) <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#1-smart-home-security-raspberry-pi" aria-label="Anchor">#</a></span></h3><ul>
<li>Detect persons, packages at door</li>
<li>Alert on phone via MQTT</li>
<li>Local storage (privacy)</li>
</ul>
<h3 id="2-wildlife-monitoring" class="relative group">2. Wildlife Monitoring <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#2-wildlife-monitoring" aria-label="Anchor">#</a></span></h3><ul>
<li>Battery-powered Pi in forest</li>
<li>Detect animals, log species</li>
<li>Solar panel for power</li>
</ul>
<h3 id="3-mobile-ar-shopping" class="relative group">3. Mobile AR Shopping <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#3-mobile-ar-shopping" aria-label="Anchor">#</a></span></h3><ul>
<li>Point camera at product</li>
<li>Detect and identify item</li>
<li>Show price, reviews overlay</li>
</ul>
<h2 id="results--metrics" class="relative group">Results &amp; Metrics <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#results--metrics" aria-label="Anchor">#</a></span></h2><p>ðŸ“Š <strong>5x faster inference</strong> on Raspberry Pi (12 FPS vs 3 FPS)<br>
ðŸ“Š <strong>4x smaller model</strong> (3MB vs 12MB)<br>
ðŸ“Š <strong>Only 2% mAP drop</strong> after quantization (37.3% â†’ 35.5%)<br>
ðŸ“Š <strong>Real-time performance</strong> on mobile (&lt;100ms latency)<br>
ðŸ“Š <strong>4 hours battery life</strong> on mobile continuous detection</p>
<h2 id="optimization-comparison" class="relative group">Optimization Comparison <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#optimization-comparison" aria-label="Anchor">#</a></span></h2><table>
  <thead>
      <tr>
          <th>Optimization</th>
          <th>Model Size</th>
          <th>FPS (Pi 4)</th>
          <th>mAP50</th>
          <th>Latency</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Baseline</strong></td>
          <td>12MB</td>
          <td>3</td>
          <td>37.3%</td>
          <td>330ms</td>
      </tr>
      <tr>
          <td><strong>Quantization</strong></td>
          <td>3MB</td>
          <td>8</td>
          <td>36.1%</td>
          <td>125ms</td>
      </tr>
      <tr>
          <td><strong>+ Pruning</strong></td>
          <td>2.5MB</td>
          <td>10</td>
          <td>35.8%</td>
          <td>100ms</td>
      </tr>
      <tr>
          <td><strong>+ NAS</strong></td>
          <td>2MB</td>
          <td>12</td>
          <td>35.5%</td>
          <td>80ms</td>
      </tr>
  </tbody>
</table>
<h2 id="demo-video" class="relative group">Demo Video <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#demo-video" aria-label="Anchor">#</a></span></h2><p>ðŸŽ¥ <strong><a href="https://youtu.be/demo-video" target="_blank" rel="noreferrer">Watch Real-Time Detection on Raspberry Pi â†’</a></strong></p>
<p>Shows live webcam feed with bounding boxes at 12 FPS.</p>
<h2 id="github-repository" class="relative group">GitHub Repository <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#github-repository" aria-label="Anchor">#</a></span></h2><p>ðŸ“‚ <strong><a href="https://github.com/0xmuler/yolo-edge-deployment" target="_blank" rel="noreferrer">View Source Code â†’</a></strong></p>
<p>Includes:</p>
<ul>
<li>Training code with PyTorch</li>
<li>Quantization and pruning scripts</li>
<li>ONNX/TFLite export pipelines</li>
<li>Raspberry Pi inference script</li>
<li>Android app (APK + source)</li>
<li>Performance benchmarking tools</li>
<li>Setup guide for Pi deployment</li>
</ul>
<h2 id="hardware-setup" class="relative group">Hardware Setup <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#hardware-setup" aria-label="Anchor">#</a></span></h2><h3 id="raspberry-pi-4-kit" class="relative group">Raspberry Pi 4 Kit <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#raspberry-pi-4-kit" aria-label="Anchor">#</a></span></h3><ul>
<li>Pi 4 Model B (2GB RAM)</li>
<li>Raspberry Pi Camera Module v2</li>
<li>Heat sinks + fan (prevents throttling)</li>
<li>32GB microSD card</li>
<li>Power supply (5V 3A)</li>
</ul>
<p><strong>Cost</strong>: ~$80 total</p>
<h3 id="software-stack" class="relative group">Software Stack <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#software-stack" aria-label="Anchor">#</a></span></h3><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#6272a4"># Install dependencies</span>
</span></span><span style="display:flex;"><span>sudo apt-get install python3-opencv
</span></span><span style="display:flex;"><span>pip install onnxruntime numpy
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#6272a4"># Run detector</span>
</span></span><span style="display:flex;"><span>python3 detect_pi.py --source <span style="color:#bd93f9">0</span>  <span style="color:#6272a4"># Webcam</span>
</span></span></code></pre></div><h2 id="challenges--solutions" class="relative group">Challenges &amp; Solutions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#challenges--solutions" aria-label="Anchor">#</a></span></h2><table>
  <thead>
      <tr>
          <th>Challenge</th>
          <th>Solution</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>Slow FPS on Pi</strong></td>
          <td>INT8 quantization, model pruning</td>
      </tr>
      <tr>
          <td><strong>High CPU temperature</strong></td>
          <td>Add heat sinks, reduce resolution</td>
      </tr>
      <tr>
          <td><strong>False positives</strong></td>
          <td>Post-processing NMS, confidence threshold</td>
      </tr>
      <tr>
          <td><strong>Battery drain on mobile</strong></td>
          <td>Frame skipping, sleep mode when idle</td>
      </tr>
  </tbody>
</table>
<h2 id="key-learnings" class="relative group">Key Learnings <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#key-learnings" aria-label="Anchor">#</a></span></h2><ol>
<li><strong>Quantization is a game-changer</strong> â€” 4x speedup with minimal accuracy loss</li>
<li><strong>Hardware matters</strong> â€” ARM optimizations (NEON) crucial for performance</li>
<li><strong>Tradeoffs everywhere</strong> â€” Accuracy vs speed vs battery vs size</li>
<li><strong>Profile before optimizing</strong> â€” Bottleneck was preprocessing, not model</li>
<li><strong>Edge has unique constraints</strong> â€” Can&rsquo;t just throw GPUs at the problem</li>
</ol>
<h2 id="benchmarking-methodology" class="relative group">Benchmarking Methodology <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#benchmarking-methodology" aria-label="Anchor">#</a></span></h2><p>Measured on 1000 frames:</p>
<ul>
<li><strong>FPS</strong>: Frames processed per second (including preprocessing)</li>
<li><strong>Latency</strong>: End-to-end time per frame (P50, P95, P99)</li>
<li><strong>mAP</strong>: Mean Average Precision @ IoU 0.5</li>
<li><strong>Model size</strong>: Disk space + RAM usage</li>
<li><strong>Power</strong>: Watts consumed (multimeter measurement)</li>
</ul>
<h2 id="future-enhancements" class="relative group">Future Enhancements <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#future-enhancements" aria-label="Anchor">#</a></span></h2><ul>
<li><strong>Multi-threaded inference</strong> â€” Overlap preprocessing + inference</li>
<li><strong>Knowledge distillation</strong> â€” Train tiny model from large teacher</li>
<li><strong>On-device training</strong> â€” Fine-tune on new classes locally</li>
<li><strong>Federated learning</strong> â€” Aggregate models from multiple Pi devices</li>
<li><strong>Hardware acceleration</strong> â€” Coral TPU, Intel Neural Compute Stick</li>
</ul>

      </div>
    </section>
    <footer class="max-w-prose pt-8 print:hidden">
      
  <div class="flex">
    
    
    
      
      
    
    <div class="place-self-center">
      
        <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
          Author
        </div>
        <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
          0xsersif
        </div>
      
      
        <div class="text-sm text-neutral-700 dark:text-neutral-400">Full-Stack Developer &amp; ML Engineer. Building web applications, websites, and production AI systems. 5+ years self-learning. HTML &amp; CSS certified.</div>
      
      <div class="text-2xl sm:text-lg">
</div>
    </div>
  </div>


      

      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="http://localhost:1313/projects/time-series-forecasting/">
              <span
                class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&larr;</span
                ><span class="ltr:hidden rtl:inline">&rarr;</span></span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Business Time-Series Forecasting</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-10-15 00:00:00 &#43;0000 UTC">15 October 2025</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="group flex text-right" href="http://localhost:1313/projects/realtime-recommender/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Real-Time Recommendation System</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-12-10 00:00:00 &#43;0000 UTC">10 December 2025</time>
                  
                </span>
              </span>
              <span
                class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&rarr;</span
                ><span class="ltr:hidden rtl:inline">&larr;</span></span
              >
            </a>
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2026
            0xsersif
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
    </div>
  </div>
  
  
</footer>

    </div>
  </body>
</html>
